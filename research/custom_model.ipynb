{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are go to extract feature from query image and all the image in the base.\n",
    "\n",
    "we will calculate entropy, roberts, sobel, gabor and average value of all pixal.\n",
    "\n",
    "Feature from every image in the input folder are captured in a hdf5 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage import io, img_as_ubyte\n",
    "import h5py\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage.color import rgb2lab, rgb2gray\n",
    "import cv2\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from image:  5afd80bec1.jpg\n",
      "Extracting features from image:  2a40de8365.jpg\n",
      "Extracting features from image:  2a242797a3.jpg\n",
      "Extracting features from image:  2dd74b37fe.jpg\n",
      "Extracting features from image:  1ebb88dff2.jpg\n",
      "Extracting features from image:  0f72117666.jpg\n",
      "Extracting features from image:  1a993de5a8.jpg\n",
      "Extracting features from image:  4c273d12a9.jpg\n",
      "Extracting features from image:  1cb123c4e9.jpg\n",
      "Extracting features from image:  6b36a20a5a.jpg\n",
      "Extracting features from image:  1d556456dc.jpg\n",
      "Extracting features from image:  2c52b24385.jpg\n",
      "Extracting features from image:  0b688923b0.jpg\n",
      "Saving features to h5 file\n"
     ]
    }
   ],
   "source": [
    "def extract_features(image):\n",
    "    #extracts color features\n",
    "    lab_image = rgb2lab(image)\n",
    "    A_image = lab_image[:,:,1]\n",
    "    A_feat = A_image.mean()\n",
    "    B_image = lab_image[:,:,2]\n",
    "    B_feat = B_image.mean()\n",
    "\n",
    "    #extracts textural features on the gray image\n",
    "    gray_image = rgb2gray(image)\n",
    "    gray_image = resize(gray_image, (256,256))\n",
    "    gray_image = img_as_ubyte(gray_image)\n",
    "\n",
    "    #entropy\n",
    "    entropy_image = entropy(gray_image, disk(3))\n",
    "    entropy_mean = entropy_image.mean()\n",
    "    entropy_std = entropy_image.std()\n",
    "    roberts_image = roberts(gray_image)\n",
    "    robert_mean = roberts_image.mean()\n",
    "    sobel_image = sobel(gray_image)\n",
    "    sobel_mean = sobel_image.mean()\n",
    "\n",
    "    #Gabor1\n",
    "    kernel1 = cv2.getGaborKernel((9, 9), 3, np.pi/4, np.pi, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    gabor1 = (cv2.filter2D(gray_image, cv2.CV_8UC3, kernel1)).mean()\n",
    "\n",
    "    #Gabor 2\n",
    "    kernel2 = cv2.getGaborKernel((9, 9), 3, np.pi/2, np.pi/4, 0.9, 0, ktype=cv2.CV_32F)\n",
    "    gabor2 = (cv2.filter2D(gray_image, cv2.CV_8UC3, kernel2)).mean()\n",
    "\n",
    "    #Gabor 3\n",
    "    kernel3 = cv2.getGaborKernel((9, 9), 5, np.pi/2, np.pi/2, 0.1, 0, ktype=cv2.CV_32F)\n",
    "    gabor3 = (cv2.filter2D(gray_image, cv2.CV_8UC3, kernel3)).mean()\n",
    "    custom_features = np.array([A_feat, B_feat, entropy_mean, entropy_std, robert_mean, sobel_mean, gabor1, gabor2, gabor3])\n",
    "\n",
    "    return custom_features\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"/Users/sudipkhadka/Desktop/mlop/semantic_search/images/\"\n",
    "\n",
    "    feats = []\n",
    "    names = []\n",
    "\n",
    "    for img in os.listdir(path):\n",
    "        print(\"Extracting features from image: \", img)\n",
    "        image = io.imread(path+img)\n",
    "\n",
    "        X = extract_features(image)\n",
    "        feats.append(X)\n",
    "        names.append(img)\n",
    "    feats = np.array(feats)\n",
    "    feature_file = \"CustomFeatures.h5\"\n",
    "    print(\"Saving features to h5 file\")\n",
    "\n",
    "    h5f = h5py.File(feature_file, \"w\")\n",
    "    h5f.create_dataset('dataset_1', data = feats)\n",
    "    h5f.create_dataset('dataset_2', data = np.string_(names))\n",
    "    h5f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
